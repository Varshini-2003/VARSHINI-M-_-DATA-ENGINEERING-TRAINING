{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"PySparkAssessment\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "xE9H_u_1AXzp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# This opens a file upload dialog in Colab\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "yNGSgVy6_03x",
        "outputId": "7c9f4225-adb9-4c53-8876-6e2a2ce30393"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0a2b68e1-c8be-419e-a3c3-09833c476b62\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0a2b68e1-c8be-419e-a3c3-09833c476b62\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving orders.csv to orders.csv\n",
            "Saving customers.csv to customers.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS50x9xt_9_Y",
        "outputId": "59038f9d-1ace-419f-8fd0-cda815560c28"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customers.csv  orders.csv  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "customers_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"customers.csv\")\n",
        "orders_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"orders.csv\")\n",
        "\n",
        "# View data\n",
        "customers_df.show()\n",
        "orders_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuv0F86DAdPX",
        "outputId": "03604268-ead6-4177-ea15-c08c3b294c7c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----------------+---------+----------+\n",
            "|CustomerID| Name|            Email|     City|SignupDate|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "|       101|  Ali|    ali@gmail.com|   Mumbai|2022-05-10|\n",
            "|       102| Neha|   neha@yahoo.com|    Delhi|2023-01-15|\n",
            "|       103| Ravi| ravi@hotmail.com|Bangalore|2021-11-01|\n",
            "|       104|Sneha|sneha@outlook.com|Hyderabad|2020-07-22|\n",
            "|       105| Amit|   amit@gmail.com|  Chennai|2023-03-10|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "\n",
            "+-------+----------+---------+-----------+--------+-------+----------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Data Ingestion & Exploration"
      ],
      "metadata": {
        "id": "_DHwnuFrAxtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# List schema\n",
        "# List all columns and data types\n",
        "customers_df.printSchema()\n",
        "orders_df.printSchema()\n",
        "\n",
        "# Count total customers and orders\n",
        "print(\"Total customers:\", customers_df.count())\n",
        "print(\"Total orders:\", orders_df.count())\n",
        "\n",
        "# Show distinct cities\n",
        "customers_df.select(\"City\").distinct().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VU2zGbrA3mG",
        "outputId": "09e9b8cd-1b9c-47f9-d054-398692dc4d2a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Email: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- SignupDate: date (nullable = true)\n",
            "\n",
            "root\n",
            " |-- OrderID: integer (nullable = true)\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Category: string (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- Price: double (nullable = true)\n",
            " |-- OrderDate: date (nullable = true)\n",
            "\n",
            "Total customers: 5\n",
            "Total orders: 7\n",
            "+---------+\n",
            "|     City|\n",
            "+---------+\n",
            "|Bangalore|\n",
            "|  Chennai|\n",
            "|   Mumbai|\n",
            "|    Delhi|\n",
            "|Hyderabad|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. DataFrame Transformations"
      ],
      "metadata": {
        "id": "MoH3nIisBZbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, year\n",
        "\n",
        "# Add TotalAmount column\n",
        "orders_df = orders_df.withColumn(\"TotalAmount\", col(\"Price\") * col(\"Quantity\"))\n",
        "\n",
        "# Extract OrderYear from OrderDate\n",
        "orders_df = orders_df.withColumn(\"OrderYear\", year(\"OrderDate\"))\n",
        "\n",
        "# Filter orders where TotalAmount > 10,000\n",
        "orders_df.filter(col(\"TotalAmount\") > 10000).show()\n",
        "\n",
        "# Drop the Email column\n",
        "customers_df = customers_df.drop(\"Email\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld6FdaZCBc7J",
        "outputId": "a6f700cb-9bd3-47f3-96b6-d810f0357510"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "|OrderID|CustomerID|Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "|      1|       101| Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|\n",
            "|      3|       102| Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|\n",
            "|      7|       102|  Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Handling Nulls & Conditionals"
      ],
      "metadata": {
        "id": "CGHuXwlfCKCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when, to_date, col\n",
        "\n",
        "# Simulate null in City\n",
        "customers_df = customers_df.withColumn(\"City\", when(col(\"CustomerID\") == 102, None).otherwise(col(\"City\")))\n",
        "customers_df = customers_df.fillna(\"Unknown\", subset=[\"City\"])\n",
        "\n",
        "# Show to confirm null was replaced with \"Unknown\"\n",
        "print(\" City column after simulating NULL and replacing with 'Unknown':\")\n",
        "customers_df.select(\"CustomerID\", \"Name\", \"City\").show()\n",
        "\n",
        "# Label customers\n",
        "customers_df = customers_df.withColumn(\n",
        "    \"CustomerType\",\n",
        "    when(to_date(\"SignupDate\") < \"2022-01-01\", \"Loyal\").otherwise(\"New\")\n",
        ")\n",
        "\n",
        "# Show to confirm CustomerType\n",
        "print(\"CustomerType based on SignupDate:\")\n",
        "customers_df.select(\"CustomerID\", \"SignupDate\", \"CustomerType\").show()\n",
        "\n",
        "# Create OrderType column in orders\n",
        "orders_df = orders_df.withColumn(\n",
        "    \"OrderType\",\n",
        "    when(col(\"TotalAmount\") < 5000, \"Low\").otherwise(\"High\")\n",
        ")\n",
        "\n",
        "# Show to confirm OrderType\n",
        "print(\"OrderType based on TotalAmount:\")\n",
        "orders_df.select(\"OrderID\", \"TotalAmount\", \"OrderType\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7mtuNaVC0zg",
        "outputId": "94f8f27c-ad98-4cfd-b03e-d3059f178e83"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " City column after simulating NULL and replacing with 'Unknown':\n",
            "+----------+-----+---------+\n",
            "|CustomerID| Name|     City|\n",
            "+----------+-----+---------+\n",
            "|       101|  Ali|   Mumbai|\n",
            "|       102| Neha|  Unknown|\n",
            "|       103| Ravi|Bangalore|\n",
            "|       104|Sneha|Hyderabad|\n",
            "|       105| Amit|  Chennai|\n",
            "+----------+-----+---------+\n",
            "\n",
            "CustomerType based on SignupDate:\n",
            "+----------+----------+------------+\n",
            "|CustomerID|SignupDate|CustomerType|\n",
            "+----------+----------+------------+\n",
            "|       101|2022-05-10|         New|\n",
            "|       102|2023-01-15|         New|\n",
            "|       103|2021-11-01|       Loyal|\n",
            "|       104|2020-07-22|       Loyal|\n",
            "|       105|2023-03-10|         New|\n",
            "+----------+----------+------------+\n",
            "\n",
            "OrderType based on TotalAmount:\n",
            "+-------+-----------+---------+\n",
            "|OrderID|TotalAmount|OrderType|\n",
            "+-------+-----------+---------+\n",
            "|      1|   100000.0|     High|\n",
            "|      2|     1200.0|      Low|\n",
            "|      3|    20000.0|     High|\n",
            "|      4|     3500.0|      Low|\n",
            "|      5|     5000.0|     High|\n",
            "|      6|     2500.0|      Low|\n",
            "|      7|    30000.0|     High|\n",
            "+-------+-----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # 4. Joins & Aggregations"
      ],
      "metadata": {
        "id": "iWAaAbTHEZZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum as _sum, count as _count\n",
        "\n",
        "# Join customers and orders on CustomerID\n",
        "joined_df = customers_df.join(orders_df, on=\"CustomerID\", how=\"inner\")\n",
        "\n",
        "# Total orders and revenue per city\n",
        "joined_df.groupBy(\"City\") \\\n",
        "    .agg(_count(\"OrderID\").alias(\"TotalOrders\"), _sum(\"TotalAmount\").alias(\"TotalRevenue\")) \\\n",
        "    .show()\n",
        "\n",
        "# Top 3 customers by total spend\n",
        "joined_df.groupBy(\"CustomerID\", \"Name\") \\\n",
        "    .agg(_sum(\"TotalAmount\").alias(\"TotalSpend\")) \\\n",
        "    .orderBy(\"TotalSpend\", ascending=False) \\\n",
        "    .show(3)\n",
        "\n",
        "# Count of products sold per category\n",
        "orders_df.groupBy(\"Category\") \\\n",
        "    .agg(_sum(\"Quantity\").alias(\"TotalProductsSold\")) \\\n",
        "    .show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vs7BirGVEXq7",
        "outputId": "4a20af9c-fd52-4a66-fe63-acee9e745f9f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+------------+\n",
            "|     City|TotalOrders|TotalRevenue|\n",
            "+---------+-----------+------------+\n",
            "|Bangalore|          1|      3500.0|\n",
            "|  Chennai|          1|      2500.0|\n",
            "|   Mumbai|          2|    101200.0|\n",
            "|  Unknown|          2|     50000.0|\n",
            "|Hyderabad|          1|      5000.0|\n",
            "+---------+-----------+------------+\n",
            "\n",
            "+----------+-----+----------+\n",
            "|CustomerID| Name|TotalSpend|\n",
            "+----------+-----+----------+\n",
            "|       101|  Ali|  101200.0|\n",
            "|       102| Neha|   50000.0|\n",
            "|       104|Sneha|    5000.0|\n",
            "+----------+-----+----------+\n",
            "only showing top 3 rows\n",
            "\n",
            "+-----------+-----------------+\n",
            "|   Category|TotalProductsSold|\n",
            "+-----------+-----------------+\n",
            "| Stationery|                5|\n",
            "|Electronics|                5|\n",
            "|  Furniture|                1|\n",
            "| Appliances|                1|\n",
            "+-----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # 5. Spark SQL Tasks"
      ],
      "metadata": {
        "id": "xYuljffWEveM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, month\n",
        "\n",
        "# Register temp views\n",
        "customers_df.createOrReplaceTempView(\"customers\")\n",
        "orders_df.createOrReplaceTempView(\"orders\")\n",
        "\n",
        "# Create and use 'sales' database\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS sales\")\n",
        "spark.sql(\"USE sales\")\n",
        "\n",
        "# Add TotalAmount column to orders_df before saving\n",
        "orders_df = orders_df.withColumn(\"TotalAmount\", col(\"Price\") * col(\"Quantity\"))\n",
        "\n",
        "# Save as tables in sales database\n",
        "customers_df.write.mode(\"overwrite\").saveAsTable(\"sales.customers\")\n",
        "orders_df.write.mode(\"overwrite\").saveAsTable(\"sales.orders\")\n",
        "\n",
        "# 1. Orders by customers from “Delhi”\n",
        "spark.sql(\"\"\"\n",
        "    SELECT o.*\n",
        "    FROM sales.orders o\n",
        "    JOIN sales.customers c ON o.CustomerID = c.CustomerID\n",
        "    WHERE c.City = 'Delhi'\n",
        "\"\"\").show()\n",
        "\n",
        "#  2. Average order value in each category\n",
        "spark.sql(\"\"\"\n",
        "    SELECT Category, ROUND(AVG(TotalAmount), 2) AS AvgOrderValue\n",
        "    FROM sales.orders\n",
        "    GROUP BY Category\n",
        "\"\"\").show()\n",
        "\n",
        "#  3. Create monthly_orders view\n",
        "spark.sql(\"\"\"\n",
        "    CREATE OR REPLACE TEMP VIEW monthly_orders AS\n",
        "    SELECT MONTH(OrderDate) AS OrderMonth,\n",
        "           SUM(TotalAmount) AS TotalAmount\n",
        "    FROM sales.orders\n",
        "    GROUP BY MONTH(OrderDate)\n",
        "\"\"\")\n",
        "\n",
        "# Show monthly_orders view\n",
        "spark.sql(\"SELECT * FROM monthly_orders ORDER BY OrderMonth\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpBTCXxwGOC0",
        "outputId": "a0dfe21c-88cc-41b4-ea24-758227e4cd1b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+\n",
            "|OrderID|CustomerID|Product|   Category|Quantity|  Price| OrderDate|TotalAmount|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+\n",
            "|      3|       102| Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|\n",
            "|      7|       102|  Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+\n",
            "\n",
            "+-----------+-------------+\n",
            "|   Category|AvgOrderValue|\n",
            "+-----------+-------------+\n",
            "| Stationery|       2500.0|\n",
            "|Electronics|      37800.0|\n",
            "|  Furniture|       3500.0|\n",
            "| Appliances|       5000.0|\n",
            "+-----------+-------------+\n",
            "\n",
            "+----------+-----------+\n",
            "|OrderMonth|TotalAmount|\n",
            "+----------+-----------+\n",
            "|         1|   101200.0|\n",
            "|         2|    28500.0|\n",
            "|         3|    32500.0|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. String & Date Functions"
      ],
      "metadata": {
        "id": "aOhxaNXJG30t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import regexp_replace, concat_ws, datediff, current_date, month, date_format\n",
        "\n",
        "# Mask emails using regex\n",
        "masked_df = customers_df.withColumn(\"MaskedEmail\", regexp_replace(\"Email\", r\"(^\\w)[^@]*(@.*)\", r\"\\1***\\2\"))\n",
        "masked_df.select(\"CustomerID\", \"Email\", \"MaskedEmail\").show()\n",
        "\n",
        "# Concatenate Name and City\n",
        "masked_df = masked_df.withColumn(\"NameFromCity\", concat_ws(\" from \", \"Name\", \"City\"))\n",
        "masked_df.select(\"NameFromCity\").show()\n",
        "\n",
        "# Customer age in days\n",
        "masked_df = masked_df.withColumn(\"CustomerAgeDays\", datediff(current_date(), \"SignupDate\"))\n",
        "masked_df.select(\"CustomerID\", \"SignupDate\", \"CustomerAgeDays\").show()\n",
        "\n",
        "# Extract month name from OrderDate\n",
        "orders_df = orders_df.withColumn(\"MonthName\", date_format(\"OrderDate\", \"MMMM\"))\n",
        "orders_df.select(\"OrderID\", \"OrderDate\", \"MonthName\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoW_KW4-G49L",
        "outputId": "68d92b81-3707-49c5-a5a5-5d670de9b56d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------+-----------+\n",
            "|CustomerID|            Email|MaskedEmail|\n",
            "+----------+-----------------+-----------+\n",
            "|       101|    ali@gmail.com|      1***2|\n",
            "|       102|   neha@yahoo.com|      1***2|\n",
            "|       103| ravi@hotmail.com|      1***2|\n",
            "|       104|sneha@outlook.com|      1***2|\n",
            "|       105|   amit@gmail.com|      1***2|\n",
            "+----------+-----------------+-----------+\n",
            "\n",
            "+--------------------+\n",
            "|        NameFromCity|\n",
            "+--------------------+\n",
            "|     Ali from Mumbai|\n",
            "|     Neha from Delhi|\n",
            "| Ravi from Bangalore|\n",
            "|Sneha from Hyderabad|\n",
            "|   Amit from Chennai|\n",
            "+--------------------+\n",
            "\n",
            "+----------+----------+---------------+\n",
            "|CustomerID|SignupDate|CustomerAgeDays|\n",
            "+----------+----------+---------------+\n",
            "|       101|2022-05-10|           1126|\n",
            "|       102|2023-01-15|            876|\n",
            "|       103|2021-11-01|           1316|\n",
            "|       104|2020-07-22|           1783|\n",
            "|       105|2023-03-10|            822|\n",
            "+----------+----------+---------------+\n",
            "\n",
            "+-------+----------+---------+\n",
            "|OrderID| OrderDate|MonthName|\n",
            "+-------+----------+---------+\n",
            "|      1|2024-01-10|  January|\n",
            "|      2|2024-01-15|  January|\n",
            "|      3|2024-02-01| February|\n",
            "|      4|2024-02-10| February|\n",
            "|      5|2024-02-15| February|\n",
            "|      6|2024-03-01|    March|\n",
            "|      7|2024-03-02|    March|\n",
            "+-------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. UDFs and Complex Logic"
      ],
      "metadata": {
        "id": "gvBiO7xWHAou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "# UDF to tag customers by spend\n",
        "def tag_customer(spend):\n",
        "    if spend > 50000:\n",
        "        return \"Gold\"\n",
        "    elif spend >= 10000:\n",
        "        return \"Silver\"\n",
        "    else:\n",
        "        return \"Bronze\"\n",
        "\n",
        "tag_udf = udf(tag_customer, StringType())\n",
        "\n",
        "# Calculate total spend and assign tag\n",
        "customer_spend_df = joined_df.groupBy(\"CustomerID\", \"Name\") \\\n",
        "    .agg(_sum(\"TotalAmount\").alias(\"TotalSpend\")) \\\n",
        "    .withColumn(\"CustomerTag\", tag_udf(\"TotalSpend\"))\n",
        "\n",
        "customer_spend_df.show()\n",
        "\n",
        "# UDF to shorten product names\n",
        "def short_product(name):\n",
        "    return name[:3] + \"...\" if name else None\n",
        "\n",
        "short_udf = udf(short_product, StringType())\n",
        "\n",
        "orders_df = orders_df.withColumn(\"ShortProduct\", short_udf(\"Product\"))\n",
        "orders_df.select(\"Product\", \"ShortProduct\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfaJIbp5HDiV",
        "outputId": "63bf4bf6-347a-4aa7-8435-d6b9f5be84ab"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+----------+-----------+\n",
            "|CustomerID| Name|TotalSpend|CustomerTag|\n",
            "+----------+-----+----------+-----------+\n",
            "|       105| Amit|    2500.0|     Bronze|\n",
            "|       104|Sneha|    5000.0|     Bronze|\n",
            "|       101|  Ali|  101200.0|       Gold|\n",
            "|       102| Neha|   50000.0|     Silver|\n",
            "|       103| Ravi|    3500.0|     Bronze|\n",
            "+----------+-----+----------+-----------+\n",
            "\n",
            "+---------+------------+\n",
            "|  Product|ShortProduct|\n",
            "+---------+------------+\n",
            "|   Laptop|      Lap...|\n",
            "|    Mouse|      Mou...|\n",
            "|   Tablet|      Tab...|\n",
            "|Bookshelf|      Boo...|\n",
            "|    Mixer|      Mix...|\n",
            "| Notebook|      Not...|\n",
            "|    Phone|      Pho...|\n",
            "+---------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Parquet & Views"
      ],
      "metadata": {
        "id": "CWzITKk8HJ2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save joined_df as Parquet\n",
        "joined_df.write.mode(\"overwrite\").parquet(\"joined_output.parquet\")\n",
        "\n",
        "# Read it back\n",
        "parquet_df = spark.read.parquet(\"joined_output.parquet\")\n",
        "parquet_df.printSchema()\n",
        "parquet_df.show()\n",
        "\n",
        "# Create global temp view\n",
        "parquet_df.createOrReplaceGlobalTempView(\"global_joined\")\n",
        "\n",
        "# Query global temp view\n",
        "spark.sql(\"SELECT * FROM global_temp.global_joined LIMIT 5\").show()\n",
        "\n",
        "# Compare CSV vs Parquet read times (timing logic optional)\n",
        "import time\n",
        "\n",
        "start_csv = time.time()\n",
        "_ = spark.read.option(\"header\", True).csv(\"orders.csv\").count()\n",
        "end_csv = time.time()\n",
        "\n",
        "start_parquet = time.time()\n",
        "_ = spark.read.parquet(\"joined_output.parquet\").count()\n",
        "end_parquet = time.time()\n",
        "\n",
        "print(\"CSV Read Time:\", end_csv - start_csv)\n",
        "print(\"Parquet Read Time:\", end_parquet - start_parquet)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EfMG37iHJZO",
        "outputId": "5eec3e57-7451-48b6-bffc-01f4beb5b217"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- SignupDate: date (nullable = true)\n",
            " |-- CustomerType: string (nullable = true)\n",
            " |-- OrderID: integer (nullable = true)\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Category: string (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- Price: double (nullable = true)\n",
            " |-- OrderDate: date (nullable = true)\n",
            " |-- TotalAmount: double (nullable = true)\n",
            " |-- OrderYear: integer (nullable = true)\n",
            " |-- OrderType: string (nullable = true)\n",
            "\n",
            "+----------+-----+---------+----------+------------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|CustomerID| Name|     City|SignupDate|CustomerType|OrderID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|OrderType|\n",
            "+----------+-----+---------+----------+------------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|       101|  Ali|   Mumbai|2022-05-10|         New|      1|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|     High|\n",
            "|       101|  Ali|   Mumbai|2022-05-10|         New|      2|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|      Low|\n",
            "|       102| Neha|  Unknown|2023-01-15|         New|      3|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|     High|\n",
            "|       103| Ravi|Bangalore|2021-11-01|       Loyal|      4|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|      Low|\n",
            "|       104|Sneha|Hyderabad|2020-07-22|       Loyal|      5|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|     High|\n",
            "|       105| Amit|  Chennai|2023-03-10|         New|      6| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|      Low|\n",
            "|       102| Neha|  Unknown|2023-01-15|         New|      7|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|     High|\n",
            "+----------+-----+---------+----------+------------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "\n",
            "+----------+-----+---------+----------+------------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|CustomerID| Name|     City|SignupDate|CustomerType|OrderID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|OrderType|\n",
            "+----------+-----+---------+----------+------------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|       101|  Ali|   Mumbai|2022-05-10|         New|      1|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|     High|\n",
            "|       101|  Ali|   Mumbai|2022-05-10|         New|      2|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|      Low|\n",
            "|       102| Neha|  Unknown|2023-01-15|         New|      3|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|     High|\n",
            "|       103| Ravi|Bangalore|2021-11-01|       Loyal|      4|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|      Low|\n",
            "|       104|Sneha|Hyderabad|2020-07-22|       Loyal|      5|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|     High|\n",
            "+----------+-----+---------+----------+------------+-------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "\n",
            "CSV Read Time: 1.8989779949188232\n",
            "Parquet Read Time: 0.9279830455780029\n"
          ]
        }
      ]
    }
  ]
}