{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gsas-rMfYnpC"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pyspark.sql import SparkSession, Row\n",
        "from pyspark.sql.functions import explode, col, when\n",
        "\n",
        "spark = SparkSession.builder.appName(\"SalesAnalysis\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    Row(OrderID=101, Customer=\"Ali\", Items=[{\"Product\":\"Laptop\", \"Qty\":1}, {\"Product\":\"Mouse\", \"Qty\":2}], Region=\"Asia\", Amount=1200.0),\n",
        "    Row(OrderID=102, Customer=\"Zara\", Items=[{\"Product\":\"Tablet\", \"Qty\":1}], Region=\"Europe\", Amount=650.0),\n",
        "    Row(OrderID=103, Customer=\"Mohan\", Items=[{\"Product\":\"Phone\", \"Qty\":2}, {\"Product\":\"Charger\", \"Qty\":1}], Region=\"Asia\", Amount=890.0),\n",
        "    Row(OrderID=104, Customer=\"Sara\", Items=[{\"Product\":\"Desk\", \"Qty\":1}], Region=\"US\", Amount=450.0)\n",
        "]\n",
        "df_sales = spark.createDataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35UfVzzbYnpE",
        "outputId": "133536b7-b669-4845-9525-1d2df0357648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- OrderID: long (nullable = true)\n",
            " |-- Customer: string (nullable = true)\n",
            " |-- Region: string (nullable = true)\n",
            " |-- Amount: double (nullable = true)\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Qty: string (nullable = true)\n",
            "\n",
            "+-------+--------+------+------+-------+---+\n",
            "|OrderID|Customer|Region|Amount|Product|Qty|\n",
            "+-------+--------+------+------+-------+---+\n",
            "|101    |Ali     |Asia  |1200.0|Laptop |1  |\n",
            "|101    |Ali     |Asia  |1200.0|Mouse  |2  |\n",
            "|102    |Zara    |Europe|650.0 |Tablet |1  |\n",
            "|103    |Mohan   |Asia  |890.0 |Phone  |2  |\n",
            "|103    |Mohan   |Asia  |890.0 |Charger|1  |\n",
            "|104    |Sara    |US    |450.0 |Desk   |1  |\n",
            "+-------+--------+------+------+-------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Q1: Flatten the Items array using explode()\n",
        "# Step 1: Explode and extract nested fields\n",
        "df_exploded = df_sales.withColumn(\"Item\", explode(\"Items\")) \\\n",
        "    .withColumn(\"Product\", col(\"Item.Product\")) \\\n",
        "    .withColumn(\"Qty\", col(\"Item.Qty\")) \\\n",
        "    .select(\"OrderID\", \"Customer\", \"Region\", \"Amount\", \"Product\", \"Qty\")\n",
        "\n",
        "# Step 2: Confirm structure\n",
        "df_exploded.printSchema()\n",
        "df_exploded.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BYyM2lnYnpF",
        "outputId": "602fdc8c-0ca4-4da4-d5fd-0387b43032ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+\n",
            "|Product|TotalQty|\n",
            "+-------+--------+\n",
            "| Laptop|       1|\n",
            "|  Mouse|       2|\n",
            "| Tablet|       1|\n",
            "|   Desk|       1|\n",
            "|  Phone|       2|\n",
            "|Charger|       1|\n",
            "+-------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Q2: Total quantity per product\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "# Cast Qty to Integer\n",
        "df_exploded = df_exploded.withColumn(\"Qty\", col(\"Qty\").cast(IntegerType()))\n",
        "\n",
        "# Now group and sum\n",
        "df_exploded.groupBy(\"Product\").sum(\"Qty\").withColumnRenamed(\"sum(Qty)\", \"TotalQty\").show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UWtrPsSYnpG",
        "outputId": "b3e06b2b-461c-4ddb-951d-db1d086a2efc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+\n",
            "|Region|OrderCount|\n",
            "+------+----------+\n",
            "|Europe|         1|\n",
            "|  Asia|         2|\n",
            "|    US|         1|\n",
            "+------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Q3: Count number of orders per region\n",
        "df_sales.groupBy(\"Region\").count().withColumnRenamed(\"count\", \"OrderCount\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mmPrvSLYnpH",
        "outputId": "93bfaad8-1064-42f1-c1cf-a1d5561582f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+--------------+\n",
            "|OrderID|Amount|HighValueOrder|\n",
            "+-------+------+--------------+\n",
            "|    101|1200.0|           Yes|\n",
            "|    102| 650.0|            No|\n",
            "|    103| 890.0|            No|\n",
            "|    104| 450.0|            No|\n",
            "+-------+------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Q4: Add column HighValueOrder\n",
        "df_sales.withColumn(\"HighValueOrder\", when(col(\"Amount\") > 1000, \"Yes\").otherwise(\"No\")) \\\n",
        "        .select(\"OrderID\", \"Amount\", \"HighValueOrder\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKdrP623YnpI",
        "outputId": "e9035c3d-ebea-4c84-caea-83d1ee470f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+------------+\n",
            "|OrderID|Region|ShippingZone|\n",
            "+-------+------+------------+\n",
            "|    101|  Asia|      Zone A|\n",
            "|    102|Europe|      Zone B|\n",
            "|    103|  Asia|      Zone A|\n",
            "|    104|    US|      Zone C|\n",
            "+-------+------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Q5: Add column ShippingZone\n",
        "df_sales.withColumn(\"ShippingZone\",\n",
        "                    when(col(\"Region\") == \"Asia\", \"Zone A\")\n",
        "                    .when(col(\"Region\") == \"Europe\", \"Zone B\")\n",
        "                    .when(col(\"Region\") == \"US\", \"Zone C\")) \\\n",
        "        .select(\"OrderID\", \"Region\", \"ShippingZone\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5y47RxRNYnpI"
      },
      "outputs": [],
      "source": [
        "# Q6: Register as Temporary View\n",
        "df_sales.createOrReplaceTempView(\"sales_view\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lew4D_RjYnpJ",
        "outputId": "94cddd08-4219-4f07-c5fb-f3a12ef1f6c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+---------+\n",
            "|Region|OrderCount|AvgAmount|\n",
            "+------+----------+---------+\n",
            "|Europe|         1|    650.0|\n",
            "|  Asia|         2|   1045.0|\n",
            "|    US|         1|    450.0|\n",
            "+------+----------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Q7: SQL query - Count orders, Avg amount by region\n",
        "spark.sql(\"\"\"\n",
        "    SELECT Region, COUNT(*) AS OrderCount, AVG(Amount) AS AvgAmount\n",
        "    FROM sales_view\n",
        "    GROUP BY Region\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "rrhZXRGbYnpJ"
      },
      "outputs": [],
      "source": [
        "# Q8: Save as permanent view (optional if Hive is enabled)\n",
        "\n",
        "df_sales.write.mode(\"overwrite\").saveAsTable(\"permanent_sales\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NndFZti3YnpK",
        "outputId": "71eab3b3-2626-43db-e19e-74d25f35489a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+--------+\n",
            "|OrderID|Customer|NumItems|\n",
            "+-------+--------+--------+\n",
            "|    101|     Ali|       2|\n",
            "|    103|   Mohan|       2|\n",
            "+-------+--------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Q9: SQL to filter all orders with more than 1 item\n",
        "spark.sql(\"\"\"\n",
        "    SELECT OrderID, Customer, size(Items) as NumItems\n",
        "    FROM sales_view\n",
        "    WHERE size(Items) > 1\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBKbbDalYnpK",
        "outputId": "0b0b4c9b-57c6-4b17-f8a1-9b143f5ff006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+\n",
            "|Customer|Amount|\n",
            "+--------+------+\n",
            "|     Ali|1200.0|\n",
            "|   Mohan| 890.0|\n",
            "+--------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Q10: SQL to extract customer names where Amount > 800\n",
        "spark.sql(\"\"\"\n",
        "    SELECT Customer, Amount\n",
        "    FROM sales_view\n",
        "    WHERE Amount > 800\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "2TD7bIOsYnpK"
      },
      "outputs": [],
      "source": [
        "# Q11: Save exploded DataFrame as partitioned Parquet file\n",
        "df_exploded.write.mode(\"overwrite\").partitionBy(\"Region\").parquet(\"/tmp/sales_partitioned\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XNo2J91YnpL",
        "outputId": "97b06c91-0330-4ae5-937a-70348f764b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+\n",
            "|Product|TotalQty|\n",
            "+-------+--------+\n",
            "|  Phone|       2|\n",
            "| Laptop|       1|\n",
            "|Charger|       1|\n",
            "|  Mouse|       2|\n",
            "|   Desk|       1|\n",
            "| Tablet|       1|\n",
            "+-------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Q12: Read back the Parquet and group by Product\n",
        "df_parquet = spark.read.parquet(\"/tmp/sales_partitioned\")\n",
        "df_parquet.groupBy(\"Product\").sum(\"Qty\").withColumnRenamed(\"sum(Qty)\", \"TotalQty\").show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}