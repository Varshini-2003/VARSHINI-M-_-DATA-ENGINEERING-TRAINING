{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zj3vZTmGJBRC"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"AggrGrouping\").getOrCreate()\n",
        "\n",
        "\n",
        "employee_data = [\n",
        "    (\"Ananya\", \"Engineering\", 60000),\n",
        "    (\"Rahul\", \"HR\", 50000),\n",
        "    (\"Priya\", \"Engineering\", 70000),\n",
        "    (\"Zoya\", \"Marketing\", 45000),\n",
        "    (\"Karan\", \"Engineering\", 75000),\n",
        "    (\"Naveen\", \"HR\", 52000),\n",
        "    (\"Fatima\", \"Marketing\", 48000)\n",
        "]\n",
        "columns_emp = [\"Name\", \"Department\", \"Salary\"]\n",
        "df_emp = spark.createDataFrame(employee_data, columns_emp)\n",
        "\n",
        "# Performance data\n",
        "performance = [\n",
        "    (\"Ananya\", 2023, 4.5),\n",
        "    (\"Rahul\", 2023, 4.9),\n",
        "    (\"Priya\", 2023, 4.3),\n",
        "    (\"Zoya\", 2023, 3.8),\n",
        "    (\"Karan\", 2023, 4.1),\n",
        "    (\"Naveen\", 2023, 4.7),\n",
        "    (\"Fatima\", 2023, 3.9)\n",
        "]\n",
        "columns_perf = [\"Name\", \"Year\", \"Rating\"]\n",
        "df_perf = spark.createDataFrame(performance, columns_perf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GroupBy and Aggregations"
      ],
      "metadata": {
        "id": "6-DZ574mJ5hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "# 1. Get the average salary by department.\n",
        "df_emp.groupBy(\"Department\").agg(avg(\"Salary\").alias(\"Avg_Salary\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6id_SJRJZAz",
        "outputId": "35d7a14c-d6a7-4da8-8ff4-74fda1c208b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------------+\n",
            "| Department|       Avg_Salary|\n",
            "+-----------+-----------------+\n",
            "|Engineering|68333.33333333333|\n",
            "|         HR|          51000.0|\n",
            "|  Marketing|          46500.0|\n",
            "+-----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Count of employees per department.\n",
        "df_emp.groupBy(\"Department\").agg(count(\"*\").alias(\"Employee_Count\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtFyIFmPKXuf",
        "outputId": "76dbb03d-e6f9-4172-df39-da71b3037894"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+\n",
            "| Department|Employee_Count|\n",
            "+-----------+--------------+\n",
            "|Engineering|             3|\n",
            "|         HR|             2|\n",
            "|  Marketing|             2|\n",
            "+-----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Maximum and minimum salary in Engineering.\n",
        "df_emp.filter(col(\"Department\") == \"Engineering\") .agg(max(\"Salary\").alias(\"Max_Salary\"), min(\"Salary\").alias(\"Min_Salary\")) .show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWXsg160Kezy",
        "outputId": "87cdb578-440b-49fa-b376-b3e4b2a50629"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|Max_Salary|Min_Salary|\n",
            "+----------+----------+\n",
            "|     75000|     60000|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Join and Combine Data"
      ],
      "metadata": {
        "id": "e0AF1ToqMVi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Perform an inner join between employee_data and performance_data on Name.\n",
        "df_joined = df_emp.join(df_perf, on=\"Name\", how=\"inner\")\n",
        "df_joined.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5gUpP-6MUqG",
        "outputId": "09de6e9a-924a-4d1a-8800-854d9c31ad4a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+----+------+\n",
            "|  Name| Department|Salary|Year|Rating|\n",
            "+------+-----------+------+----+------+\n",
            "|Ananya|Engineering| 60000|2023|   4.5|\n",
            "|Fatima|  Marketing| 48000|2023|   3.9|\n",
            "| Karan|Engineering| 75000|2023|   4.1|\n",
            "|Naveen|         HR| 52000|2023|   4.7|\n",
            "| Priya|Engineering| 70000|2023|   4.3|\n",
            "| Rahul|         HR| 50000|2023|   4.9|\n",
            "|  Zoya|  Marketing| 45000|2023|   3.8|\n",
            "+------+-----------+------+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Show each employeeâ€™s salary and performance rating.\n",
        "df_joined.select(\"Name\", \"Salary\", \"Rating\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrpBHHasMi4p",
        "outputId": "6481d55e-94a7-4c4c-dd63-9f1ad4433889"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+------+\n",
            "|  Name|Salary|Rating|\n",
            "+------+------+------+\n",
            "|Ananya| 60000|   4.5|\n",
            "|Fatima| 48000|   3.9|\n",
            "| Karan| 75000|   4.1|\n",
            "|Naveen| 52000|   4.7|\n",
            "| Priya| 70000|   4.3|\n",
            "| Rahul| 50000|   4.9|\n",
            "|  Zoya| 45000|   3.8|\n",
            "+------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Filter employees with rating > 4.5 and salary > 60000.\n",
        "df_joined.filter((col(\"Rating\") > 4.5) & (col(\"Salary\") > 60000)).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdSglNhkMqY1",
        "outputId": "ee029424-e4ab-4879-bd2e-e5217ec67886"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+------+----+------+\n",
            "|Name|Department|Salary|Year|Rating|\n",
            "+----+----------+------+----+------+\n",
            "+----+----------+------+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Window & Rank (Bonus Challenge)"
      ],
      "metadata": {
        "id": "LcWW7v6VOcXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Rank employees by salary department-wise.\n",
        "windowSpec = Window.partitionBy(\"Department\").orderBy(col(\"Salary\").desc())\n",
        "df_emp.withColumn(\"Salary_Rank\", rank().over(windowSpec)).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLza6AQaOg5u",
        "outputId": "abd41653-6153-42e9-ad89-837f00929137"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+-----------+\n",
            "|  Name| Department|Salary|Salary_Rank|\n",
            "+------+-----------+------+-----------+\n",
            "| Karan|Engineering| 75000|          1|\n",
            "| Priya|Engineering| 70000|          2|\n",
            "|Ananya|Engineering| 60000|          3|\n",
            "|Naveen|         HR| 52000|          1|\n",
            "| Rahul|         HR| 50000|          2|\n",
            "|Fatima|  Marketing| 48000|          1|\n",
            "|  Zoya|  Marketing| 45000|          2|\n",
            "+------+-----------+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum\n",
        "\n",
        "# 8. Calculate cumulative salary in each department.\n",
        "windowSpecCum = Window.partitionBy(\"Department\").orderBy(\"Salary\") \\\n",
        "                      .rowsBetween(Window.unboundedPreceding, 0)\n",
        "df_emp.withColumn(\"Cumulative_Salary\", sum(\"Salary\").over(windowSpecCum)).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMYOlo5TOkp4",
        "outputId": "f97c779b-784c-49f6-d744-4feb36cc520c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+-----------------+\n",
            "|  Name| Department|Salary|Cumulative_Salary|\n",
            "+------+-----------+------+-----------------+\n",
            "|Ananya|Engineering| 60000|            60000|\n",
            "| Priya|Engineering| 70000|           130000|\n",
            "| Karan|Engineering| 75000|           205000|\n",
            "| Rahul|         HR| 50000|            50000|\n",
            "|Naveen|         HR| 52000|           102000|\n",
            "|  Zoya|  Marketing| 45000|            45000|\n",
            "|Fatima|  Marketing| 48000|            93000|\n",
            "+------+-----------+------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Date Operations"
      ],
      "metadata": {
        "id": "5TPMgPXBPMBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Add a new column JoinDate with random dates between 2020 and 2023.\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DateType\n",
        "\n",
        "def random_date():\n",
        "    start_date = datetime(2020, 1, 1)\n",
        "    end_date = datetime(2023, 12, 31)\n",
        "    return start_date + timedelta(days=random.randint(0, (end_date - start_date).days))\n",
        "\n",
        "random_date_udf = udf(random_date, DateType())\n",
        "df_emp = df_emp.withColumn(\"JoinDate\", random_date_udf())\n",
        "df_emp.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBVAzRNjPCqa",
        "outputId": "7ef545c7-feb6-4798-de01-68ddd228aa92"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+----------+\n",
            "|  Name| Department|Salary|  JoinDate|\n",
            "+------+-----------+------+----------+\n",
            "|Ananya|Engineering| 60000|2021-05-02|\n",
            "| Rahul|         HR| 50000|2023-08-16|\n",
            "| Priya|Engineering| 70000|2020-06-25|\n",
            "|  Zoya|  Marketing| 45000|2020-12-10|\n",
            "| Karan|Engineering| 75000|2022-05-07|\n",
            "|Naveen|         HR| 52000|2020-01-08|\n",
            "|Fatima|  Marketing| 48000|2022-07-21|\n",
            "+------+-----------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Add column YearsWithCompany using current_date() and datediff().\n",
        "df_emp = df_emp.withColumn(\"YearsWithCompany\", (datediff(current_date(), col(\"JoinDate\")) / 365).cast(\"int\"))\n",
        "df_emp.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCVLih6DPR_J",
        "outputId": "0617bfc5-db13-4acf-facf-fa68880f98b1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+------+----------+----------------+\n",
            "|  Name| Department|Salary|  JoinDate|YearsWithCompany|\n",
            "+------+-----------+------+----------+----------------+\n",
            "|Ananya|Engineering| 60000|2022-03-30|               3|\n",
            "| Rahul|         HR| 50000|2021-05-24|               4|\n",
            "| Priya|Engineering| 70000|2021-07-03|               3|\n",
            "|  Zoya|  Marketing| 45000|2023-05-20|               2|\n",
            "| Karan|Engineering| 75000|2020-06-21|               4|\n",
            "|Naveen|         HR| 52000|2021-05-26|               4|\n",
            "|Fatima|  Marketing| 48000|2023-03-18|               2|\n",
            "+------+-----------+------+----------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Writing to Files"
      ],
      "metadata": {
        "id": "bNByPGiEPYYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Write the full employee DataFrame to CSV with headers.\n",
        "df_emp.write.option(\"header\", True).csv(\"output/employee_csv\")\n"
      ],
      "metadata": {
        "id": "BeAxQUgJPVg6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Save the joined DataFrame to a Parquet file.\n",
        "df_joined.write.parquet(\"output/joined_data.parquet\")\n"
      ],
      "metadata": {
        "id": "4QJ1PdQlPdSO"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}